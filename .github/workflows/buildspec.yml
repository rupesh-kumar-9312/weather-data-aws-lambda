name: Create Workflow

on:
  push:
    branches:
      - master  # Adjust this to your target branch

jobs:
  create-s3-bucket:
    runs-on: ubuntu-latest

    steps:
    - name: Set up AWS CLI
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} 
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Create S3 bucket
      run: |
        BUCKET_NAME="weather-data-api-0001"
        REGION="us-east-1"
        aws s3api create-bucket \
          --bucket $BUCKET_NAME \
          --region $REGION 
        aws s3api head-bucket --bucket $BUCKET_NAME --region $REGION || true

  check-table:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up AWS CLI
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} 
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1  # Update with your desired region

    - name: Check if DynamoDB table exists
      run: |
        TABLE_NAME="WeatherData"
        PRIMARY_KEY="Id"
        TABLE_EXISTS=$(aws dynamodb list-tables --query "TableNames[?TableName=='$TABLE_NAME']" --output text)
        if [ -z "$TABLE_EXISTS" ]; then
          echo "Table does not exist. Creating table..."
          aws dynamodb create-table \
            --table-name $TABLE_NAME \
            --key-schema \
              AttributeName=$PRIMARY_KEY,KeyType=HASH \
            --attribute-definitions \
              AttributeName=$PRIMARY_KEY,AttributeType=S \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5
        else
          echo "Table already exists."
        fi
        
  archive-and-upload:
    runs-on: ubuntu-latest
    needs: create-s3-bucket  # Ensure this job runs after the S3 bucket is created

    steps:
    - name: Set up AWS CLI
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} 
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
        
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Create temporary directory
      run: |
        mkdir temp-repo

    - name: Locate JAR file
      run: |
        JAR_FILE=$(find . -name '*.zip')
        echo "JAR file found: $JAR_FILE"
        echo "JAR_FILE_PATH=$JAR_FILE" >> $GITHUB_ENV

    - name: Upload JAR file to S3
      run: |
        BUCKET_NAME="weather-data-api-0001"
        echo "Uploading $JAR_FILE_PATH to s3://$BUCKET_NAME/"
        aws s3 cp $JAR_FILE_PATH s3://$BUCKET_NAME/ --region us-east-1 --debug
  
  deploy-lambda:
    runs-on: ubuntu-latest
    needs: archive-and-upload

    steps:
    - name: Set up AWS CLI
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} 
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Create or Update Lambda Function
      run: |
        JAR_FILE="aws-lambda-1.0-SNAPSHOT-lambda-package.zip"
        FUNCTION_NAME="WeatherDataLambda"
        ROLE_ARN="arn:aws:iam::345594602684:role/Lambda"
        BUCKET_NAME="weather-data-api-0001"
        
        # Check if Lambda function already exists
        FUNCTION_EXISTS=$(aws lambda get-function --function-name $FUNCTION_NAME 2>/dev/null || echo "not_found")
        
        if [ "$FUNCTION_EXISTS" = "not_found" ]; then
          echo "Creating Lambda function..."
          aws lambda create-function \
            --function-name $FUNCTION_NAME \
            --runtime java17 \
            --role $ROLE_ARN \
            --handler org.example.StreamLambdaHandler::handleRequest \
            --code S3Bucket=$BUCKET_NAME,S3Key=$JAR_FILE \
            --timeout 60 \
            --memory-size 512
        else
          echo "Updating Lambda function..."
          aws lambda update-function-code \
            --function-name $FUNCTION_NAME \
            --s3-bucket $BUCKET_NAME \
            --s3-key $JAR_FILE
        fi
